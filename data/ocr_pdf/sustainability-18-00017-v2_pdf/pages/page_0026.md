Sustainability 2026, 18, 17

Table 5. Cont.

|  Identified Research Gap | Research Questions | Suggested Research Approach  |
| --- | --- | --- |
|  Limited evidence on how internationalization and institutional context shape symbolic versus substantive ESG communication | How do company internationalization and institutional environments moderate the balance between symbolic-substantive reporting? | Multilevel modeling; home-vs-host institutional interaction tests; cross-regional comparative content analysis  |
|  Limited understanding of narrative micro-evidence versus systemic performance alignment | How does reliance on micro-level narrative cues influence the detection of symbolic versus substantive ESG disclosure at the firm level? | Evidence-type coding; narrative-to-KPI density analysis  |
|  Insufficient empirical evidence on how digital transparency tools influence symbolic disclosure | Do digital transparency mechanisms (e.g., real-time ESG dashboards, blockchain, AI audit trails) reduce symbolic sustainability reporting? | Pre-/post-digitalization comparisons; matched company analysis; pilot evaluations of digital traceability systems  |
|  Avenue 4: Advancing research on selective disclosure and narrative manipulation for greenwashing detection  |   |   |
|  Lack of standardization in detecting selective disclosure and narrative manipulation in sustainability reporting | Under what conditions do classifications of selective disclosure and narrative manipulation remain stable across coding protocols, sectors, and languages? | Unified codebook; multilingual NLP; manual audit and transformer-based models cross-checks; cross-industry replication with measurement-invariance tests  |
|  Limited understanding of institutional investor influence on narrative opacity and selective ESG disclosure ("disclosure fog") | Do institutional investors contribute to narrative dilution, obfuscation, and selective ESG highlighting in corporate sustainability reporting? | Mediation and moderation models; narrative-fog indices (hedging density, lexical dilution)  |
|  Limited understanding of whether and how greenwashing behaviors diffuse across companies within the same industry | To what extent do rival companies shape selective ESG narrative strategies, and how does regulatory oversight moderate these effects? | Network and spatial models; industry similarity matrices; measures of linguistic convergence (NLP)  |
|  Limited evidence on strategic topic shifting across ESG pillars as a manipulation strategy | Does selective emphasis on less material (E/S/G) pillars indicate narrative manipulation and strategic disclosure avoidance? | Topic allocation analysis; materiality-risk mapping; ESG domain imbalance indices; GRI-based thematic segmentation  |
|  Avenue 5: Advancing research on tone in sustainability reporting and its implications for detecting greenwashing  |   |   |
|  Limited adaptation of generic sentiment measures to sustainability-specific language | To what extent, and how frequently, do generic sentiment lexicons misclassify sector-specific sustainability terms as positive or negative? | Development of sustainability-specific lexicons; fine-tuning of transformer-based models on span-level CSR/ESG labels; baseline comparison; topic-level error reporting  |
|  Limited insight from document-level tone analyses | Do section-level mismatches between tone and KPI performance provide a more accurate indication of greenwashing than document-level averages? | Report segment by section (e.g., CEO letters, KPIs, targets, incidents); computation of tone for each segment; evaluation of section-level tone-KPI gaps against verified performance outcomes  |
|  Limited multimodal analysis | To what extent does positive tone co-occur with graphical manipulation or topic displacement in sustainability reports? | Integration of text tone with chart forensics and KPI coverage checks; multimodal fusion models with human adjudication  |
|  Limited research in cross-lingual and non-English sustainability reporting contexts | To what extent do tone detectors trained on English texts generalize to other languages, and do key linguistic markers exhibit similar behavior across languages? | Parallel corpora development and multilingual model transfer; validation through native-speaker adjudication; error analysis across languages and industries  |
|  Limited scope, short timeframes, and narrow sample breadth in sustainability reporting studies | Do the effects of tone analysis remain stable across industries and over time, or are they primarily driven by specific sectors or years? | Expand to multi-year, multi-industry panel datasets; apply rolling-window stability tests; employ preregistered codebooks and open-labeled text samples for reproducibility  |
|  Avenue 6: Advancing research on readability in sustainability reporting and its implications for detecting greenwashing  |   |   |
|  Generic readability formulas require adaptation for ESG-specific content | When do low readability scores indicate genuine technical complexity versus deliberate jargon or obfuscation? | Readability assessment combined with ESG specificity; claim verifiability; domain lexicons; labeling of legitimate vs. obfuscatory complexity for model training  |
|  Limited understanding of section-level tactics due to reliance on document-level scores | Does section-level readability predict disclosure-performance decoupling more accurately than report-level averages? | Report segmentation; section-level readability-gap analysis; outcome testing  |

https://doi.org/10.3390/su18010017